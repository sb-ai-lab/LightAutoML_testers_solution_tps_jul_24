{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44af725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea4d624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:51:02.113786Z",
     "iopub.status.busy": "2023-11-15T13:51:02.113289Z",
     "iopub.status.idle": "2023-11-15T13:52:02.602973Z",
     "shell.execute_reply": "2023-11-15T13:52:02.601369Z"
    },
    "papermill": {
     "duration": 60.516835,
     "end_time": "2023-11-15T13:52:02.606867",
     "exception": false,
     "start_time": "2023-11-15T13:51:02.090032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/lightautoml/transformers/text.py:22: UserWarning: 'gensim' - package isn't installed\n",
      "  warnings.warn(\"'gensim' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import median_absolute_error, accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86932369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:52:02.651810Z",
     "iopub.status.busy": "2023-11-15T13:52:02.650726Z",
     "iopub.status.idle": "2023-11-15T13:52:02.665460Z",
     "shell.execute_reply": "2023-11-15T13:52:02.663739Z"
    },
    "papermill": {
     "duration": 0.040637,
     "end_time": "2023-11-15T13:52:02.668632",
     "exception": false,
     "start_time": "2023-11-15T13:52:02.627995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def map_class(x, task, reader):\n",
    "    if task.name == 'multiclass':\n",
    "        return reader[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "mapped = np.vectorize(map_class)\n",
    "\n",
    "def score(task, y_true, y_pred):\n",
    "    if task.name == 'binary':\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    elif task.name == 'multiclass':\n",
    "        return accuracy_score(y_true, np.argmax(y_pred, 1))\n",
    "    elif task.name == 'reg' or task.name == 'multi:reg':\n",
    "        return median_absolute_error(y_true, y_pred)\n",
    "    else:\n",
    "        raise 'Task is not correct.'\n",
    "        \n",
    "def take_pred_from_task(pred, task):\n",
    "    if task.name == 'binary' or task.name == 'reg':\n",
    "        return pred[:, 0]\n",
    "    elif task.name == 'multiclass' or task.name == 'multi:reg':\n",
    "        return pred\n",
    "    else:\n",
    "        raise 'Task is not correct.'\n",
    "        \n",
    "def use_plr(USE_PLR):\n",
    "    if USE_PLR:\n",
    "        return \"plr\"\n",
    "    else:\n",
    "        return \"cont\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fda6c",
   "metadata": {
    "papermill": {
     "duration": 0.021107,
     "end_time": "2023-11-15T13:52:02.711353",
     "exception": false,
     "start_time": "2023-11-15T13:52:02.690246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.2 Constants\n",
    "\n",
    "Here we setup the constants to use in the kernel:\n",
    "- `N_THREADS` - number of vCPUs for LightAutoML model creation\n",
    "- `N_FOLDS` - number of folds in LightAutoML inner CV\n",
    "- `RANDOM_STATE` - random seed for better reproducibility\n",
    "- `TEST_SIZE` - houldout data part size \n",
    "- `TIMEOUT` - limit in seconds for model to train\n",
    "- `TARGET_NAME` - target column name in dataset\n",
    "- `TASK` - task name, 'reg', 'binary', 'multiclass', 'multi:reg'\n",
    "- `ALGOS_FOR_BLEND` - algorithms used in blending\n",
    "- `USE_PLR` - if True use PLR embedder for continuous features, else Basic Embedder\n",
    "- `TRAIN_BS` - train batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b1085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_THREADS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab63317c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:52:02.759937Z",
     "iopub.status.busy": "2023-11-15T13:52:02.758894Z",
     "iopub.status.idle": "2023-11-15T13:52:02.772003Z",
     "shell.execute_reply": "2023-11-15T13:52:02.770871Z"
    },
    "papermill": {
     "duration": 0.040349,
     "end_time": "2023-11-15T13:52:02.775425",
     "exception": false,
     "start_time": "2023-11-15T13:52:02.735076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e188954",
   "metadata": {
    "papermill": {
     "duration": 0.023074,
     "end_time": "2023-11-15T13:52:02.822731",
     "exception": false,
     "start_time": "2023-11-15T13:52:02.799657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8152835d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T13:52:02.866727Z",
     "iopub.status.busy": "2023-11-15T13:52:02.866200Z",
     "iopub.status.idle": "2023-11-15T13:52:03.377899Z",
     "shell.execute_reply": "2023-11-15T13:52:03.376300Z"
    },
    "papermill": {
     "duration": 0.537306,
     "end_time": "2023-11-15T13:52:03.381055",
     "exception": false,
     "start_time": "2023-11-15T13:52:02.843749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/playground-series-s4e7/train.csv')\n",
    "test = pd.read_csv('../input/playground-series-s4e7/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776c9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val = train_test_split(train, test_size=0.2, random_state=42, shuffle=True, stratify=train.Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a67dc48",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-15T13:52:28.576701Z",
     "iopub.status.busy": "2023-11-15T13:52:28.575802Z",
     "iopub.status.idle": "2023-11-15T14:01:34.509384Z",
     "shell.execute_reply": "2023-11-15T14:01:34.507879Z"
    },
    "papermill": {
     "duration": 545.963332,
     "end_time": "2023-11-15T14:01:34.512994",
     "exception": false,
     "start_time": "2023-11-15T13:52:28.549662",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:57:01] Stdout logging level is DEBUG.\n",
      "[20:57:01] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[20:57:01] Task: binary\n",
      "\n",
      "[20:57:01] Start automl preset with listed constraints:\n",
      "[20:57:01] - time: 2160000.00 seconds\n",
      "[20:57:01] - CPU: 16 cores\n",
      "[20:57:01] - memory: 16 GB\n",
      "\n",
      "[20:57:01] \u001b[1mTrain data shape: (11504798, 12)\u001b[0m\n",
      "\n",
      "[20:57:29] Feats was rejected during automatic roles guess: []\n",
      "[20:57:30] Layer \u001b[1m1\u001b[0m train process start. Time left 2159971.48 secs\n",
      "[20:57:56] number of text features: 0 \n",
      "[20:57:56] number of categorical features: 8 \n",
      "[20:57:56] number of continuous features: 2 \n",
      "[20:57:56] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m ...\n",
      "[20:57:56] Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': False, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'fttransformer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 10, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': True}, 'bs': 1024, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': 'UniversalDataset', 'tuned': False, 'optimization_search_space': None, 'verbose_bar': True, 'freeze_defaults': True, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': 32, 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': 'LeakyReLU', 'use_noise': False, 'use_bn': True, 'embedding_size': 32, 'cat_embedder': 'weighted', 'cont_embedder': 'plr', 'stop_by_metric': False, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'device_ids': None, 'num_dims': 2, 'text_features': [], 'bias': array([-1.96434774])}\n",
      "[20:57:57] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.249994): 100%|██████████| 8988/8988 [03:17<00:00, 45.56it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:37<00:00, 60.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:01:55] Epoch: 0, train loss: 0.24999429285526276, val loss: 0.24415138363838196, val metric: 0.8907484089947391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.242599): 100%|██████████| 8988/8988 [03:22<00:00, 44.34it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 57.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:05:58] Epoch: 1, train loss: 0.24259915947914124, val loss: 0.24316208064556122, val metric: 0.8917082937767429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.240253): 100%|██████████| 8988/8988 [03:22<00:00, 44.44it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:39<00:00, 57.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:10:00] Epoch: 2, train loss: 0.24025265872478485, val loss: 0.24330128729343414, val metric: 0.8916974710125561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:10:40] Early stopping: val loss: 0.24316208064556122, val metric: 0.8917082937767429\n",
      "[21:10:41] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.249937): 100%|██████████| 8988/8988 [03:21<00:00, 44.55it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:37<00:00, 59.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:44] Epoch: 0, train loss: 0.2499370574951172, val loss: 0.24420779943466187, val metric: 0.8904766914309885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.242462): 100%|██████████| 8988/8988 [03:22<00:00, 44.36it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:46] Epoch: 1, train loss: 0.2424623817205429, val loss: 0.24360616505146027, val metric: 0.8911217380221972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.240207): 100%|██████████| 8988/8988 [03:22<00:00, 44.48it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:37<00:00, 59.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:47] Epoch: 2, train loss: 0.24020671844482422, val loss: 0.24354694783687592, val metric: 0.8913352645145639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.238075): 100%|██████████| 8988/8988 [03:27<00:00, 43.30it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:54] Epoch: 3, train loss: 0.2380749136209488, val loss: 0.24444130063056946, val metric: 0.8906290358337016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 2248/2248 [00:37<00:00, 59.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:27:33] Early stopping: val loss: 0.24354694783687592, val metric: 0.8913352645145639\n",
      "[21:27:34] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.249983): 100%|██████████| 8988/8988 [03:23<00:00, 44.15it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 59.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:31:38] Epoch: 0, train loss: 0.2499827742576599, val loss: 0.24454419314861298, val metric: 0.890589956457504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.242573): 100%|██████████| 8988/8988 [03:28<00:00, 43.15it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:46] Epoch: 1, train loss: 0.24257341027259827, val loss: 0.24351973831653595, val metric: 0.8912594273825075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.240232): 100%|██████████| 8988/8988 [03:25<00:00, 43.84it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:39:51] Epoch: 2, train loss: 0.24023166298866272, val loss: 0.24393482506275177, val metric: 0.8913162222288626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 57.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:31] Early stopping: val loss: 0.24351973831653595, val metric: 0.8912594273825075\n",
      "[21:40:32] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.249975): 100%|██████████| 8988/8988 [03:18<00:00, 45.38it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:37<00:00, 59.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:31] Epoch: 0, train loss: 0.2499745488166809, val loss: 0.2446802705526352, val metric: 0.8902791269472483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.242513): 100%|██████████| 8988/8988 [03:19<00:00, 45.05it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:30] Epoch: 1, train loss: 0.24251268804073334, val loss: 0.2432502657175064, val metric: 0.8915126065781166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.240224): 100%|██████████| 8988/8988 [03:28<00:00, 43.20it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:39<00:00, 57.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:38] Epoch: 2, train loss: 0.24022386968135834, val loss: 0.2436305731534958, val metric: 0.8913767830861057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:18] Early stopping: val loss: 0.2432502657175064, val metric: 0.8915126065781166\n",
      "[21:53:18] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.250068): 100%|██████████| 8988/8988 [03:22<00:00, 44.31it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 59.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:57:23] Epoch: 0, train loss: 0.25006812810897827, val loss: 0.2437240183353424, val metric: 0.8912258132382742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.242651): 100%|██████████| 8988/8988 [03:27<00:00, 43.30it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:30] Epoch: 1, train loss: 0.24265095591545105, val loss: 0.24293029308319092, val metric: 0.8919983503258939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=0.240324): 100%|██████████| 8988/8988 [03:22<00:00, 44.33it/s]\n",
      "val: 100%|██████████| 2248/2248 [00:38<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:32] Epoch: 2, train loss: 0.24032406508922577, val loss: 0.2434309870004654, val metric: 0.8919275685130066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 2248/2248 [00:39<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:12] Early stopping: val loss: 0.24293029308319092, val metric: 0.8919983503258939\n",
      "[22:06:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m finished. score = \u001b[1m0.8915023652738223\u001b[0m\n",
      "[22:06:17] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m fitting and predicting completed\n",
      "[22:06:17] Time left 2155844.03 secs\n",
      "\n",
      "[22:06:17] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[22:06:17] \u001b[1mAutoml preset training completed in 4156.06 seconds\u001b[0m\n",
      "\n",
      "[22:06:17] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = Task('binary') #‘binary’ \n",
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 600 * 3600,\n",
    "    cpu_limit = 16,\n",
    "    general_params = {\"use_algos\": [['fttransformer']]}, # ['nn', 'mlp', 'dense', 'denselight', 'resnet', 'snn', 'node', 'autoint', 'fttransformer'] or custom torch model\n",
    "    nn_params = {\n",
    "        \"n_epochs\": 10, \n",
    "        \"bs\": 1024, \n",
    "        \"num_workers\": 0, \n",
    "        \"path_to_save\": None, \n",
    "        \"freeze_defaults\": True,\n",
    "        \"cont_embedder\": 'plr',\n",
    "        'cat_embedder': 'weighted',\n",
    "        \"hidden_size\": 32,\n",
    "        'embedding_size': 32,\n",
    "        'verbose_bar': True,\n",
    "        \"snap_params\": { 'k': 1, 'early_stopping': True, 'patience': 1, 'swa': True }\n",
    "    },\n",
    "    nn_pipeline_params = {\"use_qnt\": False, \"use_te\": False},\n",
    "    reader_params = {'n_jobs': 16, 'cv': 5, 'random_state': 42, 'advanced_roles': True}\n",
    ")\n",
    "\n",
    "out_of_fold_predictions = automl.fit_predict(\n",
    "    train, #valid_data=X_val,\n",
    "    roles = {\n",
    "        'target': 'Response',\n",
    "        'drop': ['id']\n",
    "    }, \n",
    "    verbose = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f88f739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915023652738223"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train.Response, out_of_fold_predictions.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aac5be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 7491/7491 [01:12<00:00, 102.99it/s]\n",
      "test: 100%|██████████| 7491/7491 [01:12<00:00, 103.89it/s]\n",
      "test: 100%|██████████| 7491/7491 [01:12<00:00, 103.79it/s]\n",
      "test: 100%|██████████| 7491/7491 [01:14<00:00, 101.18it/s]\n",
      "test: 100%|██████████| 7491/7491 [01:11<00:00, 104.14it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = automl.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b02031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fttransformer_5fold_model_089150.jbl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump((out_of_fold_predictions.data[:, 0], pred.data[:, 0]), 'fttransformer_5fold_oof_test_089150.jbl')\n",
    "joblib.dump(automl, 'fttransformer_5fold_model_089150.jbl')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6989718,
     "sourceId": 60892,
     "sourceType": "competition"
    },
    {
     "datasetId": 3815527,
     "sourceId": 6612067,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3985804,
     "sourceId": 6940442,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10466.178192,
   "end_time": "2023-11-15T16:44:45.056445",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-15T13:50:18.878253",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
